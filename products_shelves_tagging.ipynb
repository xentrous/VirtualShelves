{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier,AdaBoostClassifier,VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_file(path,sep=','):\n",
    "    \n",
    "    return pd.read_csv(path,delimiter=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def describe(file,col=None):\n",
    "    \n",
    "    print 'Columns :'\n",
    "    print list(file.columns.values)\n",
    "    if col:\n",
    "        print '\\nNull Values :',file[col].isnull().sum()\n",
    "        print '\\nUnique Values:'\n",
    "        print list(np.unique(file[col]))\n",
    "        print '\\nValue Counts :'\n",
    "        print file[col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unique(col):\n",
    "    \n",
    "    return list(np.unique(list(np.unique(train[col]))+list(np.unique(test[col]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preProcess(df):\n",
    "    \n",
    "    df=df.drop(['item_id', 'ISBN', 'Product Long Description', 'Product Name',\n",
    "               'Actual Color','Color','actual_color'],axis=1)\n",
    "    \n",
    "    #Short Description Recommended Location Aspect Ratio MPAA Rating Actors Recommended Room Recommended Use\n",
    "    #Product Short Description Seller Artist ID Literary Genre Genre ID Synopsis Item Class ID\n",
    "    \n",
    "    df.loc[df['Short Description'].isnull(),'Short Description']=' '\n",
    "    df.loc[df['Short Description']=='short description is not available','Short Description']=' '\n",
    "    df.loc[df['Recommended Location'].isnull(),'Recommended Location']=' '\n",
    "    df.loc[df['Aspect Ratio'].isnull(),'Aspect Ratio']=' '\n",
    "    df.loc[df['MPAA Rating'].isnull(),'MPAA Rating']=' '\n",
    "    df.loc[df['Actors'].isnull(),'Actors']=' '\n",
    "    df.loc[df['Recommended Room'].isnull(),'Recommended Room']=' '\n",
    "    df.loc[df['Recommended Use'].isnull(),'Recommended Use']=' '\n",
    "    df.loc[df['Product Short Description'].isnull(),'Product Short Description']=' '\n",
    "    df.loc[df['Seller'].isnull(),'Seller']=' '\n",
    "    df.loc[df['Artist ID'].isnull(),'Artist ID']=' '\n",
    "    df.loc[df['Literary Genre'].isnull(),'Literary Genre']=' '\n",
    "    df.loc[df['Publisher'].isnull(),'Publisher']=' '\n",
    "    df.loc[df['Genre ID'].isnull(),'Genre ID']=' '\n",
    "    df.loc[df['Synopsis'].isnull(),'Synopsis']=' '\n",
    "    df.loc[df['Item Class ID'].isnull(),'Item Class ID']=' '\n",
    "    \n",
    "    combined=df['Item Class ID']*10+' '+df['Short Description']+' '+df['Recommended Location']+' '+df['Aspect Ratio']+' '+df['MPAA Rating']+' '+df['Actors']+' '+df['Recommended Room']+' '+df['Recommended Use']+' ' +df['Product Short Description']+' '+df['Seller']+' '+df['Artist ID'].apply(str)+' '+df['Literary Genre']+' '+df['Publisher']+' '+df['Genre ID'].apply(str)+' '+df['Synopsis']\n",
    "    \n",
    "    df=df.drop(['Short Description','Recommended Location','Aspect Ratio','MPAA Rating','Actors',\n",
    "                'Recommended Room','Recommended Use','Product Short Description','Seller','Artist ID',\n",
    "                'Literary Genre','Publisher','Genre ID','Synopsis','Item Class ID'],axis=1)\n",
    "    \n",
    "    df=pd.concat([df,pd.DataFrame({'combined_features':combined})],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=input_file('products-shelves-tagging-dataset/train.tsv','\\t')\n",
    "test=input_file('products-shelves-tagging-dataset/test.tsv','\\t')\n",
    "item_ids=test['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#describe(train,'Short Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processing Training Data\n",
      "Pre-Processing Test Data\n"
     ]
    }
   ],
   "source": [
    "print 'Pre-Processing Training Data'\n",
    "train=preProcess(train)\n",
    "\n",
    "print 'Pre-Processing Test Data'\n",
    "test=preProcess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=-1, oob_score=False, random_state=10,\n",
      "         verbose=1, warm_start=False)\n",
      "Fitting Model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(train['combined_features'],train['tag'],test_size=0.005)\n",
    "vectorizer=TfidfVectorizer(stop_words='english')\n",
    "X_train=vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "model=BaggingClassifier(verbose=1,n_estimators=100,n_jobs=-1,random_state=10)\n",
    "print model\n",
    "\n",
    "print 'Fitting Model'\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print 'Predicting Output'\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "print y_pred\n",
    "print \"***********\"\n",
    "print y_test\n",
    "#print 'F1 Score :',classification_report(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nif __name__=='__main__':\\n    pipeline=Pipeline([('vect',TfidfVectorizer(stop_words='english')),\\n                       ('clf',LogisticRegression())])\\n    parameters={\\n        'vect__max_df':(1,10,100,1000,10000)\\n        }\\n    grid_search=GridSearchCV(pipeline,parameters,verbose=1,scoring='f1',n_jobs=-1,cv=5)\\n    grid_search.fit(X_train,y_train)\\n    print 'Best Score :',grid_search.best_score_\\n    best_parameters=grid_search.best_estimator_.get_params()\\n    for param_name in parameters.key():\\n        print param_name,best_parameters[param_name]\\n\""
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if __name__=='__main__':\n",
    "\n",
    "    pipeline=Pipeline([('vect',TfidfVectorizer(stop_words='english')),\n",
    "                       ('clf',LogisticRegression())])\n",
    "                       \n",
    "    parameters={\n",
    "        'vect__max_df':(1,10,100,1000,10000)\n",
    "        }\n",
    "        \n",
    "    grid_search=GridSearchCV(pipeline,parameters,verbose=1,scoring='f1',n_jobs=-1,cv=5)\n",
    "    \n",
    "    grid_search.fit(X_train,y_train)\n",
    "    \n",
    "    print 'Best Score :',grid_search.best_score_\n",
    "    \n",
    "    best_parameters=grid_search.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in parameters.key():\n",
    "        print param_name,best_parameters[param_name]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=-1, oob_score=False, random_state=10,\n",
      "         verbose=1, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  8.1min remaining:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  8.4min finished\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  1.4min remaining:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=BaggingClassifier(verbose=1,n_estimators=100,n_jobs=-1,random_state=10)\n",
    "print model\n",
    "\n",
    "X_train=train['combined_features']\n",
    "y_train=train['tag']\n",
    "\n",
    "test=test['combined_features']\n",
    "vectorizer=TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_train=vectorizer.fit_transform(X_train)\n",
    "test=vectorizer.transform(test)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(test)\n",
    "\n",
    "y_pred=pd.DataFrame({'tag':y_pred})\n",
    "tags=pd.concat([item_ids,y_pred],axis=1)\n",
    "tags.to_csv('tags.tsv',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
